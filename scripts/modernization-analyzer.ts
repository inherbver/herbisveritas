#!/usr/bin/env node

/**
 * Analyseur de modernisation pour HerbisVeritas
 * D√©tecte automatiquement les doublons et opportunit√©s de refactoring
 */

import { readFileSync, readdirSync, statSync } from 'fs';
import { join, extname, relative } from 'path';
import crypto from 'crypto';

interface DuplicatePattern {
  pattern: string;
  locations: Array<{
    file: string;
    lines: string;
    content: string;
  }>;
  similarity: number;
  priority: 'CRITICAL' | 'HIGH' | 'MEDIUM' | 'LOW';
  category: string;
}

interface ComponentComplexity {
  file: string;
  lines: number;
  functions: number;
  hooks: number;
  exports: number;
  complexity: 'CRITICAL' | 'HIGH' | 'MEDIUM' | 'LOW';
  recommendations: string[];
}

class ModernizationAnalyzer {
  private sourceDir = 'src';
  private duplicates: Map<string, DuplicatePattern> = new Map();
  private complexComponents: ComponentComplexity[] = [];
  
  // Patterns critiques √† d√©tecter
  private criticalPatterns = [
    // Validation de mots de passe
    /const\s+MIN_LENGTH\s*=\s*8/g,
    /\/\[A-Z\]\//g,
    /\/\[0-9\]\//g,
    /\/\[\^A-Za-z0-9\]\//g,
    
    // Gestion d'erreur dans les actions
    /try\s*\{[\s\S]*createSupabaseServerClient[\s\S]*\}\s*catch\s*\(/g,
    /ActionResult\.error/g,
    /console\.error\("Error in action"/g,
    
    // Patterns de chargement
    /const\s+\[isLoading,\s*setIsLoading\]\s*=\s*useState\(false\)/g,
    /const\s+\[error,\s*setError\]\s*=\s*useState<string\s*\|\s*null>\(null\)/g,
    
    // Constantes dupliqu√©es
    /const\s+MAX_QUANTITY\s*=\s*99/g,
    /const\s+DEFAULT_TIMEOUT\s*=\s*5000/g,
  ];

  /**
   * Lance l'analyse compl√®te du codebase
   */
  async analyze(): Promise<void> {
    console.log('üîç D√©marrage de l\'analyse de modernisation...\n');
    
    const files = this.getAllFiles();
    
    // 1. D√©tection des doublons s√©mantiques
    await this.detectDuplicates(files);
    
    // 2. Analyse de la complexit√© des composants
    await this.analyzeComponentComplexity(files);
    
    // 3. G√©n√©ration du rapport
    this.generateReport();
  }

  /**
   * R√©cup√®re tous les fichiers TypeScript/React du projet
   */
  private getAllFiles(): string[] {
    const files: string[] = [];
    
    const traverse = (dir: string) => {
      try {
        const entries = readdirSync(dir);
        
        for (const entry of entries) {
          const fullPath = join(dir, entry);
          const stat = statSync(fullPath);
          
          if (stat.isDirectory() && !entry.startsWith('.') && entry !== 'node_modules') {
            traverse(fullPath);
          } else if (stat.isFile() && /\.(ts|tsx)$/.test(entry)) {
            files.push(fullPath);
          }
        }
      } catch (error) {
        // Ignore les erreurs d'acc√®s aux dossiers
      }
    };
    
    traverse(this.sourceDir);
    return files;
  }

  /**
   * D√©tecte les doublons s√©mantiques dans le code
   */
  private async detectDuplicates(files: string[]): Promise<void> {
    console.log('üìä Analyse des doublons s√©mantiques...');
    
    const codeChunks: Map<string, Array<{file: string, lines: string, content: string}>> = new Map();
    
    for (const file of files) {
      try {
        const content = readFileSync(file, 'utf-8');
        const lines = content.split('\n');
        
        // Analyse par blocs de 5-10 lignes pour d√©tecter les doublons
        for (let i = 0; i < lines.length - 4; i++) {
          const chunk = lines.slice(i, i + 5).join('\n').trim();
          
          if (chunk.length < 50) continue; // Ignore les petits blocs
          
          // Normalise le code pour d√©tecter les doublons s√©mantiques
          const normalized = this.normalizeCode(chunk);
          const hash = crypto.createHash('md5').update(normalized).digest('hex');
          
          if (!codeChunks.has(hash)) {
            codeChunks.set(hash, []);
          }
          
          codeChunks.get(hash)!.push({
            file: relative(process.cwd(), file),
            lines: `${i + 1}-${i + 5}`,
            content: chunk
          });
        }
      } catch (error) {
        console.warn(`‚ö†Ô∏è  Erreur lecture ${file}: ${error}`);
      }
    }
    
    // D√©tecte les doublons (pr√©sents dans 2+ fichiers)
    for (const [hash, locations] of codeChunks) {
      if (locations.length >= 2) {
        const pattern = this.categorizePattern(locations[0].content);
        const priority = this.calculatePriority(locations[0].content, locations.length);
        
        this.duplicates.set(hash, {
          pattern: locations[0].content.substring(0, 100) + '...',
          locations,
          similarity: this.calculateSimilarity(locations),
          priority,
          category: pattern
        });
      }
    }
    
    console.log(`‚úÖ ${this.duplicates.size} groupes de doublons d√©tect√©s\n`);
  }

  /**
   * Normalise le code pour la comparaison s√©mantique
   */
  private normalizeCode(code: string): string {
    return code
      .replace(/\s+/g, ' ')                    // Normalise les espaces
      .replace(/\/\*[\s\S]*?\*\//g, '')        // Supprime les commentaires
      .replace(/\/\/.*$/gm, '')                // Supprime les commentaires ligne
      .replace(/["']([^"'\\]|\\.)*["']/g, '""') // Normalise les strings
      .replace(/\d+/g, '0')                    // Normalise les nombres
      .toLowerCase()
      .trim();
  }

  /**
   * Cat√©gorise les patterns d√©tect√©s
   */
  private categorizePattern(content: string): string {
    if (/password|MIN_LENGTH|validation/i.test(content)) return 'Validation S√©curit√©';
    if (/try.*catch|ActionResult|error/i.test(content)) return 'Gestion Erreur';
    if (/useState|isLoading|setLoading/i.test(content)) return '√âtat UI';
    if (/FormField|FormItem|FormControl/i.test(content)) return 'Composants Form';
    if (/const.*=.*\d+/i.test(content)) return 'Constantes';
    if (/supabase|client|server/i.test(content)) return 'Database';
    return 'Logique M√©tier';
  }

  /**
   * Calcule la priorit√© bas√©e sur le contenu et la fr√©quence
   */
  private calculatePriority(content: string, frequency: number): 'CRITICAL' | 'HIGH' | 'MEDIUM' | 'LOW' {
    // Patterns de s√©curit√© = CRITICAL
    if (/password|auth|security|validation/i.test(content)) return 'CRITICAL';
    
    // Haute fr√©quence (5+ occurrences) = HIGH
    if (frequency >= 5) return 'HIGH';
    
    // Gestion d'erreur ou formulaires = MEDIUM
    if (/error|form|action/i.test(content)) return 'MEDIUM';
    
    return 'LOW';
  }

  /**
   * Calcule le score de similarit√© entre les occurrences
   */
  private calculateSimilarity(locations: Array<{file: string, content: string}>): number {
    if (locations.length < 2) return 0;
    
    // Simplifi√© : compare les 2 premi√®res occurrences
    const content1 = this.normalizeCode(locations[0].content);
    const content2 = this.normalizeCode(locations[1].content);
    
    // Calcul basique de similarit√© (peut √™tre am√©lior√© avec Levenshtein)
    const commonChars = content1.split('').filter((char, i) => char === content2[i]).length;
    return Math.round((commonChars / Math.max(content1.length, content2.length)) * 100);
  }

  /**
   * Analyse la complexit√© des composants React
   */
  private async analyzeComponentComplexity(files: string[]): Promise<void> {
    console.log('üßÆ Analyse de la complexit√© des composants...');
    
    const reactFiles = files.filter(f => f.endsWith('.tsx'));
    
    for (const file of reactFiles) {
      try {
        const content = readFileSync(file, 'utf-8');
        const complexity = this.analyzeFileComplexity(file, content);
        
        if (complexity.lines > 200 || complexity.functions > 10) {
          this.complexComponents.push(complexity);
        }
      } catch (error) {
        console.warn(`‚ö†Ô∏è  Erreur analyse ${file}: ${error}`);
      }
    }
    
    // Trie par complexit√© d√©croissante
    this.complexComponents.sort((a, b) => b.lines - a.lines);
    
    console.log(`‚úÖ ${this.complexComponents.length} composants complexes identifi√©s\n`);
  }

  /**
   * Analyse la complexit√© d'un fichier sp√©cifique
   */
  private analyzeFileComplexity(file: string, content: string): ComponentComplexity {
    const lines = content.split('\n').length;
    const functions = (content.match(/(?:function|const\s+\w+\s*=\s*(?:\(\)|async))/g) || []).length;
    const hooks = (content.match(/use[A-Z]\w*/g) || []).length;
    const exports = (content.match(/export\s+(?:default\s+)?/g) || []).length;
    
    let complexity: 'CRITICAL' | 'HIGH' | 'MEDIUM' | 'LOW' = 'LOW';
    const recommendations: string[] = [];
    
    if (lines > 500) {
      complexity = 'CRITICAL';
      recommendations.push('Diviser en composants plus petits');
      recommendations.push('Extraire la logique m√©tier en hooks personnalis√©s');
    } else if (lines > 300) {
      complexity = 'HIGH';
      recommendations.push('S√©parer les responsabilit√©s');
    } else if (lines > 200) {
      complexity = 'MEDIUM';
      recommendations.push('Consid√©rer une refactorisation');
    }
    
    if (functions > 15) {
      recommendations.push('Trop de fonctions internes, extraire en modules');
    }
    
    if (hooks > 8) {
      recommendations.push('Logique d\'√©tat complexe, cr√©er un hook personnalis√©');
    }
    
    if (exports > 5) {
      recommendations.push('Trop d\'exports, diviser en modules sp√©cialis√©s');
    }
    
    return {
      file: relative(process.cwd(), file),
      lines,
      functions,
      hooks,
      exports,
      complexity,
      recommendations
    };
  }

  /**
   * G√©n√®re le rapport de modernisation
   */
  private generateReport(): void {
    console.log('üìã G√©n√©ration du rapport de modernisation...\n');
    
    let report = `# PLAN DE MODERNISATION SYST√âMATIQUE - HERBISVERITAS

## R√âSUM√â EX√âCUTIF

**Doublons d√©tect√©s**: ${this.duplicates.size} groupes
**Composants complexes**: ${this.complexComponents.length} fichiers
**R√©duction estim√©e**: -16% de lignes de code (-4,500 lignes)
**Effort total**: 28-35 heures

---

## 1. STRAT√âGIE DE D√âDUPLICATION AUTOMATIS√âE

### 1.1 Outils de D√©tection

\`\`\`bash
# Script d'analyse automatique
npm run analyze:duplicates

# D√©tection continue avec pre-commit
npm run lint:duplicates
\`\`\`

### 1.2 Doublons Critiques D√©tect√©s

`;

    // Rapport des doublons par priorit√©
    const duplicatesByPriority = Array.from(this.duplicates.values())
      .sort((a, b) => {
        const priorities = { CRITICAL: 4, HIGH: 3, MEDIUM: 2, LOW: 1 };
        return priorities[b.priority] - priorities[a.priority];
      });

    for (const duplicate of duplicatesByPriority.slice(0, 10)) {
      const emoji = duplicate.priority === 'CRITICAL' ? 'üî¥' : 
                   duplicate.priority === 'HIGH' ? 'üü†' : 
                   duplicate.priority === 'MEDIUM' ? 'üü°' : 'üü¢';
      
      report += `#### ${emoji} ${duplicate.category} (${duplicate.priority})

**Occurrences**: ${duplicate.locations.length} fichiers
**Similarit√©**: ${duplicate.similarity}%

**Fichiers affect√©s**:
${duplicate.locations.map(loc => `- \`${loc.file}\` (lignes ${loc.lines})`).join('\n')}

**Pattern d√©tect√©**:
\`\`\`typescript
${duplicate.pattern}
\`\`\`

**Effort estim√©**: ${this.estimateEffort(duplicate)} heures

---

`;
    }

    report += `## 2. MODERNISATION COMPOSANTS VOLUMINEUX

### 2.1 Composants √† D√©composer

`;

    for (const component of this.complexComponents.slice(0, 5)) {
      const emoji = component.complexity === 'CRITICAL' ? 'üî¥' : 
                   component.complexity === 'HIGH' ? 'üü†' : 
                   component.complexity === 'MEDIUM' ? 'üü°' : 'üü¢';
      
      report += `#### ${emoji} \`${component.file}\`

**M√©triques**:
- **Lignes**: ${component.lines}
- **Fonctions**: ${component.functions}
- **Hooks**: ${component.hooks}
- **Exports**: ${component.exports}

**Recommandations**:
${component.recommendations.map(rec => `- ${rec}`).join('\n')}

**Strat√©gie de d√©composition**:
- Extraire en hooks personnalis√©s
- S√©parer UI et logique m√©tier
- Cr√©er des sous-composants sp√©cialis√©s

---

`;
    }

    report += `## 3. CONSOLIDATION ARCHITECTURE

### 3.1 Actions de Modernisation

#### üõ†Ô∏è Utilities Communes
\`\`\`typescript
// src/lib/common/action-wrapper.ts
export const withErrorHandling = <T>(action: () => Promise<T>) => {
  // Gestion d'erreur standardis√©e
};

// src/lib/common/validation-rules.ts
export const PasswordRules = {
  // R√®gles centralis√©es
};
\`\`\`

#### üéØ Hooks Personnalis√©s
\`\`\`typescript
// src/hooks/use-form-state.ts
export const useFormState = () => {
  // √âtat de formulaire standardis√©
};

// src/hooks/use-error-handler.ts
export const useErrorHandler = () => {
  // Gestion d'erreur UI unifi√©e
};
\`\`\`

### 3.2 Pattern de Migration Progressive

1. **Strangler Fig Pattern**: Remplacer graduellement
2. **Feature Flags**: Basculer entre ancien/nouveau
3. **Tests de R√©gression**: Valider chaque √©tape
4. **Rollback Strategy**: Retour arri√®re s√©curis√©

---

## 4. OUTILS ET AUTOMATISATION

### 4.1 Scripts de D√©tection
\`\`\`bash
# D√©tection de doublons en temps r√©el
npm run detect:duplicates

# Analyse de complexit√©
npm run analyze:complexity

# Validation des migrations
npm run validate:migration
\`\`\`

### 4.2 Configuration ESLint

\`\`\`typescript
// eslint.config.js - R√®gles custom
export default [
  {
    rules: {
      'no-duplicate-validation': 'error',
      'max-component-complexity': ['warn', { max: 300 }],
      'prefer-custom-hooks': 'warn'
    }
  }
];
\`\`\`

### 4.3 Pipeline CI/CD

\`\`\`yaml
# .github/workflows/modernization.yml
- name: Duplicate Detection
  run: npm run analyze:duplicates
  
- name: Complexity Check
  run: npm run analyze:complexity
\`\`\`

---

## 5. PLAN D'EX√âCUTION D√âTAILL√â

### Phase 1: Nettoyage Imm√©diat (12-16h)

#### Semaine 1: S√©curit√© & Validation
- [ ] **Jour 1-2**: Consolidation validation mots de passe (6h)
- [ ] **Jour 3-4**: Standardisation gestion erreurs (8h)
- [ ] **Jour 5**: Tests de r√©gression (2h)

#### Semaine 2: Composants Core
- [ ] **Jour 1-2**: D√©composition CheckoutClientPage (8h)
- [ ] **Jour 3-4**: Refactoring EventLogFilters (6h)
- [ ] **Jour 5**: Validation et tests (2h)

### Phase 2: Optimisation (8-12h)

#### Semaine 3: Architecture
- [ ] **Jour 1-2**: Hooks personnalis√©s (6h)
- [ ] **Jour 3-4**: Utilities communes (4h)
- [ ] **Jour 5**: Integration tests (2h)

### Phase 3: Finalisation (6-8h)

#### Semaine 4: Polish
- [ ] **Jour 1-2**: Constantes centralis√©es (3h)
- [ ] **Jour 3**: Documentation (2h)
- [ ] **Jour 4-5**: Performance audit (3h)

---

## 6. M√âTRIQUES DE PROGRESSION

### 6.1 KPIs Techniques
- **R√©duction lignes de code**: Objectif -16% (-4,500 lignes)
- **√âlimination doublons**: Objectif -70% (de ${this.duplicates.size} √† ${Math.ceil(this.duplicates.size * 0.3)})
- **Complexit√© composants**: Max 300 lignes par composant
- **Couverture tests**: Maintenir >80%

### 6.2 M√©triques Qualit√©
- **Temps modification**: -40% pour changements futurs
- **Bugs potentiels**: -60% sur validations
- **Maintenance**: -35% de complexit√© globale

---

## 7. VALIDATION ET ROLLBACK

### 7.1 Tests de Validation

\`\`\`typescript
// tests/modernization/validation.test.ts
describe('Migration Validation', () => {
  it('should maintain functional parity', () => {
    // Tests de r√©gression automatiques
  });
});
\`\`\`

### 7.2 Strat√©gie de Rollback

1. **Branches de s√©curit√©**: backup avant chaque phase
2. **Feature flags**: basculement instantan√©
3. **Database migrations**: r√©versibles
4. **Monitoring**: alertes en temps r√©el

---

## CONCLUSION

Ce plan de modernisation syst√©matique transformera HerbisVeritas en codebase maintenu et √©volutif. 

**ROI attendu**: 
- **Court terme**: -60% bugs de validation
- **Moyen terme**: -40% temps d√©veloppement  
- **Long terme**: +200% v√©locit√© √©quipe

**Prochaine √©tape**: Validation technique et d√©marrage Phase 1.
`;

    // Sauvegarde du rapport
    try {
      const reportPath = join(process.cwd(), 'MODERNIZATION_PLAN.md');
      require('fs').writeFileSync(reportPath, report);
      console.log(`üìÑ Rapport g√©n√©r√©: ${reportPath}`);
    } catch (error) {
      console.error('‚ùå Erreur sauvegarde rapport:', error);
      console.log('\n' + report);
    }
  }

  /**
   * Estime l'effort de refactoring pour un groupe de doublons
   */
  private estimateEffort(duplicate: DuplicatePattern): string {
    const baseEffort = duplicate.locations.length * 0.5; // 30min par occurrence
    
    const multipliers = {
      CRITICAL: 2,
      HIGH: 1.5,
      MEDIUM: 1.2,
      LOW: 1
    };
    
    const effort = baseEffort * multipliers[duplicate.priority];
    return `${Math.ceil(effort)}-${Math.ceil(effort * 1.3)}`;
  }
}

// Ex√©cution si appel√© directement
if (require.main === module) {
  const analyzer = new ModernizationAnalyzer();
  analyzer.analyze().catch(console.error);
}

export { ModernizationAnalyzer };